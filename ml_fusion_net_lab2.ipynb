{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "id": "dWUpjmddpQYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install noisereduce"
      ],
      "metadata": {
        "id": "nWFMZzy7xvrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "A174HftXyB5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BrtmnpkqnxY0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "from python_speech_features import *\n",
        "import re\n",
        "from tensorflow_hub import load, Module\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error\n",
        "import noisereduce as nr\n",
        "import contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/data_ML5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_q1Ng_9n5Tt",
        "outputId": "c91b80d9-e517-4098-98fd-8c4b423bab55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/data_ML5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train_split_Depression_AVEC2017.csv')\n",
        "test_df = pd.read_csv('dev_split_Depression_AVEC2017.csv')"
      ],
      "metadata": {
        "id": "Flmz-l8roQ3v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "test_id = test_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "# train_label = train_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "# test_label = test_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "train_label = train_df[['PHQ8_Score']]['PHQ8_Score'].tolist()\n",
        "test_label = test_df[['PHQ8_Score']]['PHQ8_Score'].tolist()"
      ],
      "metadata": {
        "id": "F0kmPjWZwhlr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo = load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]"
      ],
      "metadata": {
        "id": "sqJAQF0Q3-V7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "topics = []\n",
        "with open('questions.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        topics.append(line.strip('\\n').strip())"
      ],
      "metadata": {
        "id": "-dDYofyv08e_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    sentence = re.sub(r'\\(|\\)', '', sentence)\n",
        "    pattern = r'\\b(what|how|where|when|why|are|do|have|who|who\\'s|what\\'s|why\\'d|what\\'d)\\b(.*)$'\n",
        "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "    if match:\n",
        "        question = match.group(0).strip()\n",
        "        if question in topics:\n",
        "          return True\n",
        "    return False\n",
        "\n",
        "def expanding_contractions(text):\n",
        "  # expanding contractions\n",
        "  expanded_words = []\n",
        "  for word in text.split():\n",
        "  # using contractions.fix to expand the shortened words\n",
        "    expanded_words.append(contractions.fix(word))\n",
        "\n",
        "  text = ' '.join(expanded_words)\n",
        "  return text\n",
        "\n",
        "def extract_features(number, features, target, targets, mode):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    wavefile = wave.open('{0}_AUDIO.wav'.format(number, 'r'))\n",
        "    framerate = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "    reduced_noise = nr.reduce_noise(y=wave_data, sr=framerate)\n",
        "\n",
        "    time_range = []\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    start_time = 0\n",
        "    stop_time = 0\n",
        "    signal = []\n",
        "\n",
        "    global counter_train, counter_test\n",
        "\n",
        "    for row in transcript.itertuples():\n",
        "        if row.speaker == 'Ellie':\n",
        "            content = row.value.strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response.strip())\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response)\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif row.speaker == 'Participant':\n",
        "            if 'scrubbed_entry' in row.value:\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +row.value.split('\\n')[0].strip()\n",
        "            start_time = int(row.start_time*framerate)\n",
        "            stop_time = int(row.stop_time*framerate)\n",
        "            signal = np.hstack((signal, reduced_noise[start_time:stop_time].astype(np.float64)))\n",
        "    # print(responses)\n",
        "    clip = framerate*15\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      text_feature = elmo(tf.constant(responses))[\"elmo\"]\n",
        "      text_feature = tf.reduce_mean(text_feature, axis=0)\n",
        "      #if target == 1 and mode == 'train':\n",
        "      if target >= 10 and mode == 'train':\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "              if clip*(i+1) > len(signal):\n",
        "                continue\n",
        "              melspec = librosa.feature.melspectrogram(y=signal[clip*i:clip*(i+1)], n_mels=80,sr=framerate)\n",
        "              text_f = text_feature[i*10:(i+1)*10]\n",
        "              features.append([text_f.numpy(), melspec])\n",
        "              targets.append(target)\n",
        "              counter_train+=1\n",
        "      else:\n",
        "          melspec = librosa.feature.melspectrogram(y=signal[:clip], n_mels=80, sr=framerate)\n",
        "          text_f = text_feature[:10]\n",
        "          features.append([text_f.numpy(), melspec])\n",
        "          targets.append(target)"
      ],
      "metadata": {
        "id": "FheXV1zp1gZL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "train_features = []\n",
        "train_targets = []\n",
        "\n",
        "# test set\n",
        "test_features = []\n",
        "test_targets = []\n",
        "\n",
        "\n",
        "counter_train = 0"
      ],
      "metadata": {
        "id": "8akwUx70ww85"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_id)):\n",
        "    extract_features(train_id[i], train_features, train_label[i], train_targets, 'train')\n",
        "\n",
        "print(np.shape(train_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mX0tZee0qzc",
        "outputId": "0b14d303-cd30-4238-b2f1-fadf5c5c1497"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "304\n",
            "305\n",
            "310\n",
            "312\n",
            "313\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "330\n",
            "333\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "343\n",
            "344\n",
            "345\n",
            "347\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "360\n",
            "362\n",
            "363\n",
            "364\n",
            "366\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "374\n",
            "375\n",
            "376\n",
            "379\n",
            "380\n",
            "383\n",
            "385\n",
            "386\n",
            "391\n",
            "392\n",
            "393\n",
            "397\n",
            "400\n",
            "401\n",
            "402\n",
            "409\n",
            "412\n",
            "414\n",
            "415\n",
            "416\n",
            "419\n",
            "423\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "433\n",
            "434\n",
            "437\n",
            "441\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "459\n",
            "463\n",
            "464\n",
            "468\n",
            "471\n",
            "473\n",
            "474\n",
            "475\n",
            "478\n",
            "479\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "491\n",
            "(154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_id)):\n",
        "    extract_features(test_id[i], test_features, test_label[i], test_targets, 'test')\n",
        "\n",
        "print(np.shape(test_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCldF81x_XuZ",
        "outputId": "7f3b7065-ede5-4005-ed14-b9ce039b86a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302\n",
            "307\n",
            "331\n",
            "335\n",
            "346\n",
            "367\n",
            "377\n",
            "381\n",
            "382\n",
            "388\n",
            "389\n",
            "390\n",
            "395\n",
            "403\n",
            "404\n",
            "406\n",
            "413\n",
            "417\n",
            "418\n",
            "420\n",
            "422\n",
            "436\n",
            "439\n",
            "440\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "476\n",
            "477\n",
            "482\n",
            "483\n",
            "484\n",
            "489\n",
            "490\n",
            "492\n",
            "(33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_train_samples_clas_lab2.npz', train_features)\n",
        "np.savez('fuse_test_samples_clas_lab2.npz', test_features)\n",
        "np.savez('fuse_train_labels_clas_lab2.npz', train_targets)\n",
        "np.savez('fuse_test_labels_clas_lab2.npz', test_targets)\n",
        "\n"
      ],
      "metadata": {
        "id": "qqiBVOi4jVXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_train_samples_reg_lab2.npz', train_features)\n",
        "np.savez('fuse_test_samples_reg_lab2.npz', test_features)\n",
        "np.savez('fuse_train_labels_reg_lab2.npz', train_targets)\n",
        "np.savez('fuse_test_labels_reg_lab2.npz', test_targets)"
      ],
      "metadata": {
        "id": "VGmpEBO-Y8t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## classification"
      ],
      "metadata": {
        "id": "MsjDIn2qY_ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('fuse_train_samples_clas_lab2.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('fuse_test_samples_clas_lab2.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_clas_lab2.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_clas_lab2.npz', allow_pickle=True)['arr_0']\n",
        "\n",
        "X_train = np.array(features_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_train = np.array(targets_train)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "32fcmxIgjbW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train[i][1]]).astype('float32')\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test[i][1]]).astype('float32')"
      ],
      "metadata": {
        "id": "thY-UFDJkFIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(Y_train)\n",
        "test_y = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "KH7Ytmt_-YV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = []\n",
        "audio_features = []\n",
        "for i in range(len(X_train)):\n",
        "  text_features.append(X_train[i][0])\n",
        "  audio_features.append(X_train[i][1])\n",
        "\n",
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "for i in range(len(X_test)):\n",
        "  text_features_test.append(X_test[i][0])\n",
        "  audio_features_test.append(X_test[i][1])\n",
        "\n",
        "text_features = np.array(text_features)\n",
        "audio_features = np.array(audio_features)\n",
        "\n",
        "text_features_test = np.array(text_features_test)\n",
        "audio_features_test = np.array(audio_features_test)"
      ],
      "metadata": {
        "id": "Oa38uPcE-c4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "input1 = Input(shape=(80, 469, 1))\n",
        "x1 = Conv2D(32, (1, 7), activation='relu', input_shape=(80, 469, 1))(input1)\n",
        "x1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(x1)\n",
        "x1 = Conv2D(32, (1, 7), activation='relu')(x1)\n",
        "x1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=(10, 1024))\n",
        "\n",
        "forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(input2)\n",
        "final_hidden_state = forward_state + backward_state\n",
        "\n",
        "x2 = attention(output, final_hidden_state)\n",
        "\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Flatten()(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(merged)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "model.fit([audio_features, text_features], train_y, validation_data=([audio_features_test, text_features_test], test_y), epochs=10, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kciiDkvg_xpi",
        "outputId": "3826bd96-e784-4679-a6ef-447e2ff831f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "76/76 [==============================] - 13s 51ms/step - loss: 0.7120 - accuracy: 0.3841 - val_loss: 0.7015 - val_accuracy: 0.3636\n",
            "Epoch 2/10\n",
            "76/76 [==============================] - 3s 45ms/step - loss: 0.6787 - accuracy: 0.5960 - val_loss: 0.6817 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "76/76 [==============================] - 5s 69ms/step - loss: 0.6526 - accuracy: 0.7020 - val_loss: 0.6345 - val_accuracy: 0.7273\n",
            "Epoch 4/10\n",
            "76/76 [==============================] - 4s 55ms/step - loss: 0.5716 - accuracy: 0.8146 - val_loss: 0.6390 - val_accuracy: 0.7273\n",
            "Epoch 5/10\n",
            "76/76 [==============================] - 3s 45ms/step - loss: 0.5104 - accuracy: 0.9007 - val_loss: 0.5943 - val_accuracy: 0.7273\n",
            "Epoch 6/10\n",
            "76/76 [==============================] - 3s 45ms/step - loss: 0.4412 - accuracy: 0.9272 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
            "Epoch 7/10\n",
            "76/76 [==============================] - 6s 77ms/step - loss: 0.3642 - accuracy: 0.9536 - val_loss: 0.5067 - val_accuracy: 0.7879\n",
            "Epoch 8/10\n",
            "76/76 [==============================] - 4s 46ms/step - loss: 0.3130 - accuracy: 0.9470 - val_loss: 0.5237 - val_accuracy: 0.7273\n",
            "Epoch 9/10\n",
            "76/76 [==============================] - 3s 45ms/step - loss: 0.2448 - accuracy: 0.9735 - val_loss: 0.5514 - val_accuracy: 0.6970\n",
            "Epoch 10/10\n",
            "76/76 [==============================] - 3s 46ms/step - loss: 0.1978 - accuracy: 0.9868 - val_loss: 0.4620 - val_accuracy: 0.7273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d8ea44f6e30>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([audio_features_test, text_features_test])\n",
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(Y_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC2utRfnFDcQ",
        "outputId": "5d8b5814-3bb9-4564-c700-413f32ab4c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d8f521348b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 29ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77        21\n",
            "           1       0.60      0.75      0.67        12\n",
            "\n",
            "    accuracy                           0.73        33\n",
            "   macro avg       0.72      0.73      0.72        33\n",
            "weighted avg       0.75      0.73      0.73        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## regression"
      ],
      "metadata": {
        "id": "iQJDySEyJzol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('fuse_train_samples_reg_lab2.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('fuse_test_samples_reg_lab2.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_reg_lab2.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_reg_lab2.npz', allow_pickle=True)['arr_0']\n",
        "\n",
        "X_train = np.array(features_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_train = np.array(targets_train)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "V7qDoP5HJ0oU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train[i][1]]).astype('float32')\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test[i][1]]).astype('float32')"
      ],
      "metadata": {
        "id": "0z-pS56WZM0Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = []\n",
        "audio_features = []\n",
        "for i in range(len(X_train)):\n",
        "  text_features.append(X_train[i][0])\n",
        "  audio_features.append(X_train[i][1])\n",
        "\n",
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "for i in range(len(X_test)):\n",
        "  text_features_test.append(X_test[i][0])\n",
        "  audio_features_test.append(X_test[i][1])\n",
        "\n",
        "text_features = np.array(text_features)\n",
        "audio_features = np.array(audio_features)\n",
        "\n",
        "text_features_test = np.array(text_features_test)\n",
        "audio_features_test = np.array(audio_features_test)"
      ],
      "metadata": {
        "id": "njGpcgXPZcth"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "input1 = Input(shape=(80, 469, 1))\n",
        "x1 = Conv2D(32, (1, 7), activation='relu', input_shape=(80, 469, 1))(input1)\n",
        "x1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(x1)\n",
        "x1 = Conv2D(32, (1, 7), activation='relu')(x1)\n",
        "x1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=(10, 1024))\n",
        "\n",
        "forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(input2)\n",
        "final_hidden_state = forward_state + backward_state\n",
        "\n",
        "x2 = attention(output, final_hidden_state)\n",
        "\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = tf.keras.layers.Dense(1, activation='linear')(merged)"
      ],
      "metadata": {
        "id": "FgHKQwW9ZkVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "model.fit([audio_features, text_features], Y_train, validation_data=([audio_features_test, text_features_test], Y_test), epochs=15, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19EtPQcPZm8F",
        "outputId": "45235816-979b-4f2f-e187-c9345a85657d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "76/76 [==============================] - 7s 36ms/step - loss: 54.7416 - mean_absolute_error: 5.9733 - val_loss: 41.9370 - val_mean_absolute_error: 5.4943\n",
            "Epoch 2/15\n",
            "76/76 [==============================] - 4s 47ms/step - loss: 34.4448 - mean_absolute_error: 4.7778 - val_loss: 39.5637 - val_mean_absolute_error: 5.2360\n",
            "Epoch 3/15\n",
            "76/76 [==============================] - 4s 47ms/step - loss: 29.9947 - mean_absolute_error: 4.4572 - val_loss: 39.5167 - val_mean_absolute_error: 5.4828\n",
            "Epoch 4/15\n",
            "76/76 [==============================] - 2s 22ms/step - loss: 21.5953 - mean_absolute_error: 3.5815 - val_loss: 31.4347 - val_mean_absolute_error: 4.7141\n",
            "Epoch 5/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 14.7962 - mean_absolute_error: 2.8991 - val_loss: 36.4295 - val_mean_absolute_error: 5.2590\n",
            "Epoch 6/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 10.4933 - mean_absolute_error: 2.4471 - val_loss: 36.2098 - val_mean_absolute_error: 5.1623\n",
            "Epoch 7/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 6.6682 - mean_absolute_error: 2.0121 - val_loss: 31.9183 - val_mean_absolute_error: 4.7741\n",
            "Epoch 8/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 4.3505 - mean_absolute_error: 1.5772 - val_loss: 34.9482 - val_mean_absolute_error: 4.9761\n",
            "Epoch 9/15\n",
            "76/76 [==============================] - 2s 32ms/step - loss: 2.1915 - mean_absolute_error: 1.0995 - val_loss: 34.6736 - val_mean_absolute_error: 4.9433\n",
            "Epoch 10/15\n",
            "76/76 [==============================] - 3s 33ms/step - loss: 1.5452 - mean_absolute_error: 0.9209 - val_loss: 38.7426 - val_mean_absolute_error: 5.2816\n",
            "Epoch 11/15\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 1.1289 - mean_absolute_error: 0.8315 - val_loss: 32.5769 - val_mean_absolute_error: 4.6763\n",
            "Epoch 12/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.6692 - mean_absolute_error: 0.6234 - val_loss: 34.4590 - val_mean_absolute_error: 4.9174\n",
            "Epoch 13/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.4207 - mean_absolute_error: 0.5047 - val_loss: 34.0239 - val_mean_absolute_error: 4.8649\n",
            "Epoch 14/15\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.3407 - mean_absolute_error: 0.4400 - val_loss: 34.2568 - val_mean_absolute_error: 4.9277\n",
            "Epoch 15/15\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.3166 - mean_absolute_error: 0.4416 - val_loss: 33.1561 - val_mean_absolute_error: 4.7249\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c256c13b7c0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate([audio_features_test, text_features_test], Y_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")\n",
        "y_pred = model.predict([audio_features_test, text_features_test])\n",
        "print(np.sqrt(mean_squared_error(Y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s38VdUQ-ZtQs",
        "outputId": "951fae4b-cb87-43f6-acb1-778c2f054620"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 14ms/step - loss: 33.1561 - mean_absolute_error: 4.7249\n",
            "Test Loss: 33.156131744384766, Test Mean Absolute Error: 4.724878787994385\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "5.758136283403365\n"
          ]
        }
      ]
    }
  ]
}