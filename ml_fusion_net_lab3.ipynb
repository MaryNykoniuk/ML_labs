{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Audio"
      ],
      "metadata": {
        "id": "j-82vl49xQQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FBgpINLj6iPV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "import re\n",
        "from tensorflow_hub import load, Module\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input, LSTM, Bidirectional, RNN,  GRU, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import contractions\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop, Adam, Adadelta\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "import noisereduce as nr\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/data_ml5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6U_ida267eL",
        "outputId": "b8f5457d-2a37-4948-a083-75e7ca545479"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/data_ml5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split_df = pd.read_csv('train_split_Depression_AVEC2017.csv')\n",
        "test_split_df = pd.read_csv('dev_split_Depression_AVEC2017.csv')\n",
        "train_split_num = train_split_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "test_split_num = test_split_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "# train_split_clabel = train_split_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "# test_split_clabel = test_split_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "train_split_clabel = train_split_df[['PHQ8_Score']]['PHQ8_Score'].tolist()\n",
        "test_split_clabel = test_split_df[['PHQ8_Score']]['PHQ8_Score'].tolist()"
      ],
      "metadata": {
        "id": "T6L8an-p7BZK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(number, audio_features, target, audio_targets, mode):\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    wavefile = wave.open('{0}_AUDIO.wav'.format(number, 'r'))\n",
        "    sample_rate = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "    reduced_noise = nr.reduce_noise(y=wave_data, sr=sr)\n",
        "\n",
        "    start_time = 0\n",
        "    stop_time = 0\n",
        "\n",
        "    signal = []\n",
        "\n",
        "    global counter_train\n",
        "\n",
        "    for t in transcript.itertuples():\n",
        "        if getattr(t,'speaker') == 'Ellie':\n",
        "            continue\n",
        "        elif getattr(t,'speaker') == 'Participant':\n",
        "            if 'scrubbed_entry' in getattr(t,'value'):\n",
        "                continue\n",
        "            start_time = int(getattr(t,'start_time')*sample_rate)\n",
        "            stop_time = int(getattr(t,'stop_time')*sample_rate)\n",
        "            signal = np.hstack((signal, reduced_noise[start_time:stop_time].astype(float)))\n",
        "\n",
        "    clip = sample_rate*1*15\n",
        "    if target == 1 and mode == 'train':\n",
        "    # if target >= 10 and mode == 'train':\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "            if clip*(i+1) > len(signal):\n",
        "                continue\n",
        "            sample = signal[clip*i:clip*(i+1)]\n",
        "            melspec = librosa.feature.melspectrogram(y=sample, n_mels=80,sr=sample_rate)\n",
        "            audio_features.append(melspec)\n",
        "            audio_targets.append(target)\n",
        "            counter_train+=1\n",
        "    else:\n",
        "        sample = signal[:clip]\n",
        "        melspec = librosa.feature.melspectrogram(y=sample, n_mels=80, sr=sample_rate)\n",
        "        audio_features.append(melspec)\n",
        "        audio_targets.append(target)\n",
        "    print(melspec.shape)\n",
        "    print('{}_P feature done'.format(number))"
      ],
      "metadata": {
        "id": "g0azA-Koes7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features_train = []\n",
        "audio_ctargets_train = []\n",
        "counter_train = 0\n",
        "\n",
        "for index in range(len(train_split_num)):\n",
        "    extract_features(train_split_num[index], audio_features_train, train_split_clabel[index], audio_ctargets_train, 'train')\n"
      ],
      "metadata": {
        "id": "G16KDtPb-8Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "audio_features_test = []\n",
        "audio_ctargets_test = []\n",
        "\n",
        "for index in range(len(test_split_num)):\n",
        "    extract_features(test_split_num[index], audio_features_test, test_split_clabel[index], audio_ctargets_test, 'test')\n",
        "\n",
        "print(np.shape(audio_ctargets_train), np.shape(audio_ctargets_test))"
      ],
      "metadata": {
        "id": "AWSgTAn4fbaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('features/train_samples_cla.npz', audio_features_train)\n",
        "np.savez('features/test_samples_cla.npz', audio_features_test)\n",
        "np.savez('features/train_labels_cla.npz', audio_ctargets_train)\n",
        "np.savez('features/test_labels_cla.npz', audio_ctargets_test)"
      ],
      "metadata": {
        "id": "8U3gCTgB_CNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('features/train_samples_cla.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('features/test_samples_cla.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('features/train_labels_cla.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('features/test_labels_cla.npz', allow_pickle=True)['arr_0']"
      ],
      "metadata": {
        "id": "YNbjsDOvi9eH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(features_train)\n",
        "Y_train = np.array(targets_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "j6l8UitbjCKq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n",
        "X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])"
      ],
      "metadata": {
        "id": "9mFdLPrjjGro"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fzoFfVjLoD",
        "outputId": "54b9326d-26aa-4c4d-853b-38f593b042cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(153, 80, 469)\n",
            "(153,)\n",
            "(35, 80, 469)\n",
            "(35,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(Y_train)\n",
        "test_y = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "-aRUww7EjP0P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "LURcoue4MHe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32, 3, activation='relu', input_shape=(80, 469)))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, train_y, epochs=15, batch_size=8, validation_data=(X_test, test_y))"
      ],
      "metadata": {
        "id": "8UUMTnp5u7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c519c2-e2d8-4ffa-c816-2a3547d9c57c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 7s 118ms/step - loss: 0.6932 - accuracy: 0.4706 - val_loss: 0.6931 - val_accuracy: 0.5429\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 0.6931 - accuracy: 0.4706 - val_loss: 0.6947 - val_accuracy: 0.3429\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 0.6928 - accuracy: 0.4967 - val_loss: 0.6957 - val_accuracy: 0.3429\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 0.6924 - accuracy: 0.4967 - val_loss: 0.6975 - val_accuracy: 0.3429\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 0.6919 - accuracy: 0.4967 - val_loss: 0.6960 - val_accuracy: 0.3429\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 0.6911 - accuracy: 0.4967 - val_loss: 0.6994 - val_accuracy: 0.3429\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.6891 - accuracy: 0.4967 - val_loss: 0.7004 - val_accuracy: 0.3429\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.6853 - accuracy: 0.5686 - val_loss: 0.6976 - val_accuracy: 0.4286\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 0.6724 - accuracy: 0.7059 - val_loss: 0.7052 - val_accuracy: 0.4571\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 0.6286 - accuracy: 0.7124 - val_loss: 0.7418 - val_accuracy: 0.5143\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4945 - accuracy: 0.8497 - val_loss: 0.9877 - val_accuracy: 0.5143\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.3602 - accuracy: 0.9150 - val_loss: 1.0686 - val_accuracy: 0.6571\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.2347 - accuracy: 0.9542 - val_loss: 1.0581 - val_accuracy: 0.6857\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.1422 - accuracy: 0.9608 - val_loss: 1.1231 - val_accuracy: 0.7429\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 0.0804 - accuracy: 0.9804 - val_loss: 0.9857 - val_accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae97b6532b0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, test_y)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(Y_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhE7AyGONhJ_",
        "outputId": "a8d5db28-2da5-418b-fbeb-d7a76f9d0c65"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step - loss: 0.9857 - accuracy: 0.7714\n",
            "Test Loss: 0.9856722354888916, Test Accuracy: 0.7714285850524902\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.74      0.81        23\n",
            "           1       0.62      0.83      0.71        12\n",
            "\n",
            "    accuracy                           0.77        35\n",
            "   macro avg       0.76      0.79      0.76        35\n",
            "weighted avg       0.80      0.77      0.78        35\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ],
      "metadata": {
        "id": "pN_nJ6OudALP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('features/train_samples_reg.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('features/test_samples_reg.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('features/train_labels_reg.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('features/test_labels_reg.npz', allow_pickle=True)['arr_0']"
      ],
      "metadata": {
        "id": "L4JW7X5CdgMV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(features_train)\n",
        "Y_train = np.array(targets_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "aj9hxNsedxq1"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32, 3, activation='relu', input_shape=(80, 469)))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])\n",
        "\n",
        "model.fit(X_train,Y_train,batch_size=4,epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSvPBu6Md-S3",
        "outputId": "7773e18b-de51-44f7-8da2-f53e3f8ea434"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "39/39 [==============================] - 6s 20ms/step - loss: 108.7297 - mean_absolute_error: 8.6373\n",
            "Epoch 2/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 102.6986 - mean_absolute_error: 8.3268\n",
            "Epoch 3/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 94.9049 - mean_absolute_error: 7.9490\n",
            "Epoch 4/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 81.9712 - mean_absolute_error: 7.3632\n",
            "Epoch 5/15\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 63.0287 - mean_absolute_error: 6.3814\n",
            "Epoch 6/15\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 47.9408 - mean_absolute_error: 5.6684\n",
            "Epoch 7/15\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 39.6455 - mean_absolute_error: 5.2848\n",
            "Epoch 8/15\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 35.5722 - mean_absolute_error: 5.0499\n",
            "Epoch 9/15\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 34.6597 - mean_absolute_error: 4.9925\n",
            "Epoch 10/15\n",
            "39/39 [==============================] - 1s 32ms/step - loss: 34.9328 - mean_absolute_error: 4.9646\n",
            "Epoch 11/15\n",
            "39/39 [==============================] - 1s 22ms/step - loss: 35.2768 - mean_absolute_error: 5.0239\n",
            "Epoch 12/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 35.6947 - mean_absolute_error: 5.0430\n",
            "Epoch 13/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 33.8952 - mean_absolute_error: 4.8818\n",
            "Epoch 14/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 34.8749 - mean_absolute_error: 5.0040\n",
            "Epoch 15/15\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 33.9984 - mean_absolute_error: 4.9149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae914ebad70>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fATKJQi1mTB0",
        "outputId": "2dc43bde-9fb9-42bb-92e0-b2106d0d400e"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step - loss: 33.0534 - mean_absolute_error: 4.9541\n",
            "Test Loss: 33.05341720581055, Test Mean Absolute Error: 4.954130172729492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(np.sqrt(mean_squared_error(Y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9By1Ru_Zmdg8",
        "outputId": "f851d67f-7d55-4742-8a96-518e7c61b2d3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 12ms/step\n",
            "5.749210283188846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text"
      ],
      "metadata": {
        "id": "ZR9cs8KwxM8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = []\n",
        "with open('questions.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        topics.append(line.strip('\\n').strip())"
      ],
      "metadata": {
        "id": "-A7x3F7bxOZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    sentence = re.sub(r'\\(|\\)', '', sentence)\n",
        "    pattern = r'\\b(what|how|where|when|why|are|do|have|who|who\\'s|what\\'s|why\\'d|what\\'d)\\b(.*)$'\n",
        "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "    if match:\n",
        "        question = match.group(0).strip()\n",
        "        if question in topics:\n",
        "          return True\n",
        "    return False\n",
        "\n",
        "def expanding_contractions(text):\n",
        "  expanded_words = []\n",
        "  for word in text.split():\n",
        "\n",
        "    expanded_words.append(contractions.fix(word))\n",
        "\n",
        "  text = ' '.join(expanded_words)\n",
        "  return text\n",
        "\n",
        "def extract_features(number, features, target, targets, mode):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    signal = []\n",
        "\n",
        "    global counter_train\n",
        "\n",
        "    for row in transcript.itertuples():\n",
        "        if row.speaker == 'Ellie':\n",
        "\n",
        "            content = row.value.strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response.strip())\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response)\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif row.speaker == 'Participant':\n",
        "            if 'scrubbed_entry' in row.value:\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +row.value.split('\\n')[0].strip()\n",
        "\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      # if target == 1 and mode == 'train':\n",
        "      if target >= 10 and mode == 'train':\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "              if 10*(i+1) > len(responses):\n",
        "                continue\n",
        "              text_f = responses[i*10:(i+1)*10]\n",
        "              features.append(text_f)\n",
        "              targets.append(target)\n",
        "              counter_train+=1\n",
        "      else:\n",
        "          text_f = responses[:10]\n",
        "          features.append(text_f)\n",
        "          targets.append(target)"
      ],
      "metadata": {
        "id": "y-xbu4Tmx4yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter_train = 0\n",
        "\n",
        "text_features_train = []\n",
        "text_ctargets_train = []\n",
        "\n",
        "for i in range(len(train_split_num)):\n",
        "    extract_features(train_split_num[i], text_features_train,  train_split_clabel[i], text_ctargets_train, 'train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3VwdJL4zpIn",
        "outputId": "b7f2d0a8-a1f7-4558-f977-c91e23b9e254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "304\n",
            "305\n",
            "310\n",
            "312\n",
            "313\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "330\n",
            "333\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "343\n",
            "344\n",
            "345\n",
            "347\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "360\n",
            "362\n",
            "363\n",
            "364\n",
            "366\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "374\n",
            "375\n",
            "376\n",
            "379\n",
            "380\n",
            "383\n",
            "385\n",
            "386\n",
            "391\n",
            "392\n",
            "393\n",
            "397\n",
            "400\n",
            "401\n",
            "402\n",
            "409\n",
            "412\n",
            "414\n",
            "415\n",
            "416\n",
            "419\n",
            "423\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "433\n",
            "434\n",
            "437\n",
            "441\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "459\n",
            "463\n",
            "464\n",
            "468\n",
            "471\n",
            "473\n",
            "474\n",
            "475\n",
            "478\n",
            "479\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_features_test = []\n",
        "text_ctargets_test = []\n",
        "\n",
        "for i in range(len(test_split_num)):\n",
        "    extract_features(test_split_num[i], text_features_test, test_split_clabel[i], text_ctargets_test, 'test')\n",
        "\n",
        "print(np.shape(text_features_train), np.shape(text_features_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-cCWoQX1n_b",
        "outputId": "664d122a-45c3-4a8e-8d21-01ce3ba15e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302\n",
            "307\n",
            "331\n",
            "335\n",
            "346\n",
            "367\n",
            "377\n",
            "381\n",
            "382\n",
            "388\n",
            "389\n",
            "390\n",
            "395\n",
            "403\n",
            "404\n",
            "406\n",
            "413\n",
            "417\n",
            "418\n",
            "420\n",
            "422\n",
            "436\n",
            "439\n",
            "440\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "476\n",
            "477\n",
            "482\n",
            "483\n",
            "484\n",
            "489\n",
            "490\n",
            "492\n",
            "(154, 10) (33, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(sublist) for sublist in text_features_train]\n",
        "np.shape(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MnSjBow2S3u",
        "outputId": "9ffcaf91-bcfa-4373-8925-1079d064d957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = [' '.join(sublist) for sublist in text_features_test]"
      ],
      "metadata": {
        "id": "QpnmmCDV3KMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = list(text_ctargets_train)\n",
        "Y_test = list(text_ctargets_test)"
      ],
      "metadata": {
        "id": "qrn1VoqS3m0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(Y_train)\n",
        "test_y = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "JH5FCoOF3-rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "3-2a9Glw3v4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "C4TCL2i34BJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "By-gn5RLGJr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(name='inputs',shape=[max_len])\n",
        "\n",
        "layer = Embedding(max_words,100,input_length=max_len)(inputs)\n",
        "layer = GRU(64, return_sequences=True)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = GRU(128, return_sequences=False)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = Dense(2,name='out_layer')(layer)\n",
        "layer = Activation('softmax')(layer)\n",
        "model = Model(inputs=inputs,outputs=layer)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VnX4UhRF4Dg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix,train_y,batch_size=4,epochs=10, validation_data=(test_sequences_matrix, test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12hX6eR94aQa",
        "outputId": "b1adec63-324d-4130-f624-6e2aed2f5389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 13s 172ms/step - loss: 0.6927 - accuracy: 0.5294 - val_loss: 0.6910 - val_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 7s 188ms/step - loss: 0.6916 - accuracy: 0.5556 - val_loss: 0.6912 - val_accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 7s 183ms/step - loss: 0.6892 - accuracy: 0.6144 - val_loss: 0.6914 - val_accuracy: 0.5758\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 6s 156ms/step - loss: 0.6873 - accuracy: 0.6405 - val_loss: 0.6876 - val_accuracy: 0.6667\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 0.6824 - accuracy: 0.6601 - val_loss: 0.6856 - val_accuracy: 0.6970\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 5s 141ms/step - loss: 0.6756 - accuracy: 0.7712 - val_loss: 0.6820 - val_accuracy: 0.7273\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 6s 165ms/step - loss: 0.6585 - accuracy: 0.7974 - val_loss: 0.6693 - val_accuracy: 0.7273\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 7s 189ms/step - loss: 0.6137 - accuracy: 0.8431 - val_loss: 0.6224 - val_accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 5s 139ms/step - loss: 0.4687 - accuracy: 0.8301 - val_loss: 0.5194 - val_accuracy: 0.7273\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 8s 196ms/step - loss: 0.3126 - accuracy: 0.8758 - val_loss: 0.4720 - val_accuracy: 0.7879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x780f69affbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences_matrix)\n",
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(Y_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lBkjk7L4rVx",
        "outputId": "f86ea53d-554a-467e-af08-7512a7f22874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 3s 59ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83        21\n",
            "           1       0.69      0.75      0.72        12\n",
            "\n",
            "    accuracy                           0.79        33\n",
            "   macro avg       0.77      0.78      0.77        33\n",
            "weighted avg       0.79      0.79      0.79        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ],
      "metadata": {
        "id": "cbSkFTGkGMAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "QFq32xuZGwW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "Wqp30UxBGzJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(name='inputs',shape=[max_len])\n",
        "\n",
        "layer = Embedding(max_words,100,input_length=max_len)(inputs)\n",
        "layer = GRU(64, return_sequences=True)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = GRU(128, return_sequences=False)(layer)\n",
        "layer = Dropout(0.3)(layer)\n",
        "layer = Dense(1,name='out_layer')(layer)\n",
        "layer = Activation('linear')(layer)\n",
        "model = Model(inputs=inputs,outputs=layer)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])\n",
        "\n",
        "model.fit(sequences_matrix,Y_train,batch_size=4,epochs=10, validation_data=(test_sequences_matrix, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hpyc-FM46iy",
        "outputId": "c111162b-4a3f-49db-bbc9-372842181011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 12s 172ms/step - loss: 105.9960 - mean_absolute_error: 8.4830 - val_loss: 79.6350 - val_mean_absolute_error: 6.8398\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 101.3067 - mean_absolute_error: 8.2632 - val_loss: 71.4100 - val_mean_absolute_error: 6.3977\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 7s 170ms/step - loss: 53.6652 - mean_absolute_error: 5.9190 - val_loss: 43.4985 - val_mean_absolute_error: 5.5882\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 8s 198ms/step - loss: 37.6220 - mean_absolute_error: 5.0872 - val_loss: 35.8473 - val_mean_absolute_error: 5.2153\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 10s 259ms/step - loss: 33.5753 - mean_absolute_error: 4.8557 - val_loss: 36.3294 - val_mean_absolute_error: 5.2376\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 6s 156ms/step - loss: 34.9698 - mean_absolute_error: 5.0040 - val_loss: 36.8150 - val_mean_absolute_error: 5.2577\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 32.9013 - mean_absolute_error: 4.8295 - val_loss: 34.3425 - val_mean_absolute_error: 5.1347\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 6s 155ms/step - loss: 33.7224 - mean_absolute_error: 4.9127 - val_loss: 36.1445 - val_mean_absolute_error: 5.2334\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 7s 175ms/step - loss: 33.1439 - mean_absolute_error: 4.7981 - val_loss: 35.4152 - val_mean_absolute_error: 5.2044\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 7s 191ms/step - loss: 32.0855 - mean_absolute_error: 4.7311 - val_loss: 34.5844 - val_mean_absolute_error: 5.1658\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x780f4d7207c0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate(test_sequences_matrix, Y_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIHac8Qcu1fB",
        "outputId": "1fa1cd68-4145-414f-c393-8a3e008e6b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 26ms/step - loss: 34.5844 - mean_absolute_error: 5.1658\n",
            "Test Loss: 34.58436584472656, Test Mean Absolute Error: 5.165834903717041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences_matrix)\n",
        "print(np.sqrt(mean_squared_error(Y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-zEFtoNJ58Y",
        "outputId": "1279f749-a655-4039-cf98-83c9509e4fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 37ms/step\n",
            "5.880847177270091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusion"
      ],
      "metadata": {
        "id": "pnIl0mKMv1-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = []\n",
        "with open('questions.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        topics.append(line.strip('\\n').strip())"
      ],
      "metadata": {
        "id": "cHwj8rMAv5b5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    sentence = re.sub(r'\\(|\\)', '', sentence)\n",
        "    pattern = r'\\b(what|how|where|when|why|are|do|have|who|who\\'s|what\\'s|why\\'d|what\\'d)\\b(.*)$'\n",
        "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "    if match:\n",
        "        question = match.group(0).strip()\n",
        "        if question in topics:\n",
        "          return True\n",
        "    return False\n",
        "\n",
        "def expanding_contractions(text):\n",
        "  expanded_words = []\n",
        "  for word in text.split():\n",
        "\n",
        "    expanded_words.append(contractions.fix(word))\n",
        "\n",
        "  text = ' '.join(expanded_words)\n",
        "  return text\n",
        "\n",
        "def extract_features(number, text_features, audio_features, target, targets, mode):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    wavefile = wave.open('{0}_AUDIO.wav'.format(number, 'r'))\n",
        "    framerate = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "    reduced_noise = nr.reduce_noise(y=wave_data, sr=framerate)\n",
        "\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    signal = []\n",
        "\n",
        "    global counter_train\n",
        "\n",
        "    for row in transcript.itertuples():\n",
        "        if row.speaker == 'Ellie':\n",
        "            content = row.value.strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response.strip())\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    response = expanding_contractions(response)\n",
        "                    response = re.sub(r'[^\\w\\s]', '', response)\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif row.speaker == 'Participant':\n",
        "            if 'scrubbed_entry' in row.value:\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +row.value.split('\\n')[0].strip()\n",
        "            start_time = int(row.start_time*framerate)\n",
        "            stop_time = int(row.stop_time*framerate)\n",
        "            signal = np.hstack((signal, reduced_noise[start_time:stop_time].astype(np.float64)))\n",
        "    # print(responses)\n",
        "    clip = framerate*15\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      # if target == 1 and mode == 'train':\n",
        "      if target >= 10 and mode == 'train':\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "              if clip*(i+1) > len(signal) or 10*(i+1) > len(responses):\n",
        "                continue\n",
        "              melspec = librosa.feature.melspectrogram(y=signal[clip*i:clip*(i+1)], n_mels=80,sr=framerate)\n",
        "              text_f = responses[i*10:(i+1)*10]\n",
        "              text_features.append(text_f)\n",
        "              audio_features.append(melspec)\n",
        "              targets.append(target)\n",
        "              counter_train+=1\n",
        "      else:\n",
        "          melspec = librosa.feature.melspectrogram(y=signal[:clip], n_mels=80, sr=framerate)\n",
        "          text_f = responses[:10]\n",
        "          text_features.append(text_f)\n",
        "          audio_features.append(melspec)\n",
        "          targets.append(target)"
      ],
      "metadata": {
        "id": "jBEqDO7vyY_R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "text_features = []\n",
        "audio_features = []\n",
        "train_targets = []\n",
        "\n",
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "test_targets = []\n",
        "counter_train = 0"
      ],
      "metadata": {
        "id": "U2VIhzZw0msn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_split_num)):\n",
        "    extract_features(train_split_num[i], text_features, audio_features, train_split_clabel[i], train_targets, 'train')\n",
        "\n",
        "print(np.shape(train_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQgFLUqh0m3W",
        "outputId": "c3a0be13-360e-4360-f55a-85504771b41b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "304\n",
            "305\n",
            "310\n",
            "312\n",
            "313\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "330\n",
            "333\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "343\n",
            "344\n",
            "345\n",
            "347\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "360\n",
            "362\n",
            "363\n",
            "364\n",
            "366\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "374\n",
            "375\n",
            "376\n",
            "379\n",
            "380\n",
            "383\n",
            "385\n",
            "386\n",
            "391\n",
            "392\n",
            "393\n",
            "397\n",
            "400\n",
            "401\n",
            "402\n",
            "409\n",
            "412\n",
            "414\n",
            "415\n",
            "416\n",
            "419\n",
            "423\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "433\n",
            "434\n",
            "437\n",
            "441\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "459\n",
            "463\n",
            "464\n",
            "468\n",
            "471\n",
            "473\n",
            "474\n",
            "475\n",
            "478\n",
            "479\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "491\n",
            "(154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "test_targets = []\n",
        "\n",
        "for i in range(len(test_split_num)):\n",
        "    extract_features(test_split_num[i], text_features_test, audio_features_test, test_split_clabel[i], test_targets, 'test')\n",
        "\n",
        "print(np.shape(test_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJxEx2Tz1xCQ",
        "outputId": "728e5819-5da5-4543-9bc8-c3bc777068e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302\n",
            "307\n",
            "331\n",
            "335\n",
            "346\n",
            "367\n",
            "377\n",
            "381\n",
            "382\n",
            "388\n",
            "389\n",
            "390\n",
            "395\n",
            "403\n",
            "404\n",
            "406\n",
            "413\n",
            "417\n",
            "418\n",
            "420\n",
            "422\n",
            "436\n",
            "439\n",
            "440\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "476\n",
            "477\n",
            "482\n",
            "483\n",
            "484\n",
            "489\n",
            "490\n",
            "492\n",
            "(33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_train_text_samples_clas_lab3.npz', text_features)\n",
        "np.savez('fuse_train_audio_samples_clas_lab3.npz', audio_features)\n",
        "np.savez('fuse_test_text_samples_clas_lab3.npz', text_features_test)\n",
        "np.savez('fuse_test_audio_samples_clas_lab3.npz', audio_features_test)\n",
        "np.savez('fuse_train_labels_clas_lab3.npz', train_targets)\n",
        "np.savez('fuse_test_labels_clas_lab3.npz', test_targets)\n"
      ],
      "metadata": {
        "id": "2DzY-z336yWR"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_train_text_samples_reg_lab3.npz', text_features)\n",
        "np.savez('fuse_train_audio_samples_reg_lab3.npz', audio_features)\n",
        "np.savez('fuse_test_text_samples_reg_lab3.npz', text_features_test)\n",
        "np.savez('fuse_test_audio_samples_reg_lab3.npz', audio_features_test)\n",
        "np.savez('fuse_train_labels_reg_lab3.npz', train_targets)\n",
        "np.savez('fuse_test_labels_reg_lab3.npz', test_targets)"
      ],
      "metadata": {
        "id": "-CqgrorlHBtZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features_train = np.load('fuse_train_text_samples_clas_lab3.npz', allow_pickle=True)['arr_0']\n",
        "audio_features_train = np.load('fuse_train_audio_samples_clas_lab3.npz', allow_pickle=True)['arr_0']\n",
        "text_features_test = np.load('fuse_test_text_samples_clas_lab3.npz', allow_pickle=True)['arr_0']\n",
        "audio_features_test = np.load('fuse_test_audio_samples_clas_lab3.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_clas_lab3.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_clas_lab3.npz', allow_pickle=True)['arr_0']"
      ],
      "metadata": {
        "id": "JgozFti_8nTD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_features_train.shape)\n",
        "print(audio_features_train.shape)\n",
        "print(text_features_test.shape)\n",
        "print(audio_features_test.shape)\n",
        "print(targets_train.shape)\n",
        "print(ctargets_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CccrOa8V9Q5T",
        "outputId": "db8388e3-7746-4e61-e256-25fe19f718cd"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(153, 10)\n",
            "(153, 80, 469)\n",
            "(33, 10)\n",
            "(33, 80, 469)\n",
            "(153,)\n",
            "(33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in audio_features_train])\n",
        "audio_features_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in audio_features_test])"
      ],
      "metadata": {
        "id": "e91AK3uZ9IlT"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = [' '.join(sublist) for sublist in text_features_train]\n",
        "X_test_text = [' '.join(sublist) for sublist in text_features_test]\n",
        "np.shape(X_train_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dedYS6F19wc3",
        "outputId": "4d3811f8-0cff-48e8-92d8-58499b344004"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153,)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(targets_train)\n",
        "test_y = to_categorical(ctargets_test)"
      ],
      "metadata": {
        "id": "mrCz2OzK-FJq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train_text)\n",
        "sequences = tok.texts_to_sequences(X_train_text)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "qmd4KHr1-R5f"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test_text)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "OhVxfqEH-Zpl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "lLKGjZa9_ldW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(80,469))\n",
        "x1 = Conv1D(32, 3, activation='relu')(input1)\n",
        "x1 = MaxPooling1D(pool_size=4)(x1)\n",
        "x1 = LSTM(units=64, return_sequences=True)(x1)\n",
        "x1 = Dropout(0.2)(x1)\n",
        "x1 = LSTM(units=64, return_sequences=False)(x1)\n",
        "x1 = Dropout(0.2)(x1)\n",
        "x1 = Dense(units=32, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=[max_len])\n",
        "x2 = Embedding(max_words,100,input_length=max_len)(input2)\n",
        "x2 = GRU(64, return_sequences=True)(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "x2 = GRU(128, return_sequences=False)(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = Dense(2, activation='softmax')(merged)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "model.fit([audio_features_train, sequences_matrix], train_y, epochs=10, batch_size=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os0okYFu_mpw",
        "outputId": "b8aa71a5-a3d2-47ab-b053-8526a90125ea"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "39/39 [==============================] - 21s 216ms/step - loss: 0.6935 - accuracy: 0.4967\n",
            "Epoch 2/10\n",
            "39/39 [==============================] - 8s 200ms/step - loss: 0.6928 - accuracy: 0.5229\n",
            "Epoch 3/10\n",
            "39/39 [==============================] - 7s 187ms/step - loss: 0.6897 - accuracy: 0.6013\n",
            "Epoch 4/10\n",
            "39/39 [==============================] - 9s 230ms/step - loss: 0.6863 - accuracy: 0.7255\n",
            "Epoch 5/10\n",
            "39/39 [==============================] - 7s 191ms/step - loss: 0.6785 - accuracy: 0.8562\n",
            "Epoch 6/10\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 0.6449 - accuracy: 0.7647\n",
            "Epoch 7/10\n",
            "39/39 [==============================] - 7s 188ms/step - loss: 0.4662 - accuracy: 0.8497\n",
            "Epoch 8/10\n",
            "39/39 [==============================] - 9s 235ms/step - loss: 0.2463 - accuracy: 0.9020\n",
            "Epoch 9/10\n",
            "39/39 [==============================] - 7s 180ms/step - loss: 0.1441 - accuracy: 0.9477\n",
            "Epoch 10/10\n",
            "39/39 [==============================] - 10s 260ms/step - loss: 0.0758 - accuracy: 0.9739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5f859bf8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([audio_features_test, test_sequences_matrix])\n",
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(ctargets_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr1rRELLAtdF",
        "outputId": "903f5a95-b19e-4816-a42f-ef97805fa97d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 57ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.81      0.85        21\n",
            "           1       0.71      0.83      0.77        12\n",
            "\n",
            "    accuracy                           0.82        33\n",
            "   macro avg       0.80      0.82      0.81        33\n",
            "weighted avg       0.83      0.82      0.82        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ],
      "metadata": {
        "id": "qOXsPirjHKNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_features_train = np.load('fuse_train_text_samples_reg_lab3.npz', allow_pickle=True)['arr_0']\n",
        "audio_features_train = np.load('fuse_train_audio_samples_reg_lab3.npz', allow_pickle=True)['arr_0']\n",
        "text_features_test = np.load('fuse_test_text_samples_reg_lab3.npz', allow_pickle=True)['arr_0']\n",
        "audio_features_test = np.load('fuse_test_audio_samples_reg_lab3.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_reg_lab3.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_reg_lab3.npz', allow_pickle=True)['arr_0']"
      ],
      "metadata": {
        "id": "5FnqElDLHLlp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in audio_features_train])\n",
        "audio_features_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in audio_features_test])"
      ],
      "metadata": {
        "id": "JE-3cXcVHxis"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = [' '.join(sublist) for sublist in text_features_train]\n",
        "X_test_text = [' '.join(sublist) for sublist in text_features_test]\n",
        "np.shape(X_train_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeBgLZPFH0CT",
        "outputId": "accd3591-4e6e-4a0d-df5b-e7ac6e200580"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train_text)\n",
        "sequences = tok.texts_to_sequences(X_train_text)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "nl6jdNk0IMEI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test_text)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "ImukM3CSIOW9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(80,469))\n",
        "x1 = Conv1D(32, 3, activation='relu')(input1)\n",
        "x1 = MaxPooling1D(pool_size=4)(x1)\n",
        "x1 = LSTM(units=64, return_sequences=True)(x1)\n",
        "x1 = Dropout(0.2)(x1)\n",
        "x1 = LSTM(units=64, return_sequences=False)(x1)\n",
        "x1 = Dropout(0.2)(x1)\n",
        "x1 = Dense(units=32, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=[max_len])\n",
        "x2 = Embedding(max_words,100,input_length=max_len)(input2)\n",
        "x2 = GRU(64, return_sequences=True)(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "x2 = GRU(128, return_sequences=False)(x2)\n",
        "x2 = Dropout(0.3)(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = Dense(1, activation='linear')(merged)\n",
        "\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])\n",
        "\n",
        "model.fit([audio_features_train, sequences_matrix], targets_train, validation_data=([audio_features_test, test_sequences_matrix], ctargets_test), epochs=15, batch_size=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QaohjZiITEU",
        "outputId": "dea87869-4928-4f85-a274-5a307352951f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "39/39 [==============================] - 23s 285ms/step - loss: 105.5893 - mean_absolute_error: 8.4700 - val_loss: 87.7878 - val_mean_absolute_error: 7.1472\n",
            "Epoch 2/15\n",
            "39/39 [==============================] - 7s 178ms/step - loss: 96.5105 - mean_absolute_error: 8.0422 - val_loss: 67.7537 - val_mean_absolute_error: 6.1026\n",
            "Epoch 3/15\n",
            "39/39 [==============================] - 9s 228ms/step - loss: 47.1310 - mean_absolute_error: 5.4299 - val_loss: 43.2411 - val_mean_absolute_error: 5.8354\n",
            "Epoch 4/15\n",
            "39/39 [==============================] - 6s 163ms/step - loss: 34.9224 - mean_absolute_error: 4.9210 - val_loss: 41.2182 - val_mean_absolute_error: 5.6978\n",
            "Epoch 5/15\n",
            "39/39 [==============================] - 9s 229ms/step - loss: 34.3729 - mean_absolute_error: 4.8630 - val_loss: 39.8474 - val_mean_absolute_error: 5.6255\n",
            "Epoch 6/15\n",
            "39/39 [==============================] - 6s 164ms/step - loss: 34.8057 - mean_absolute_error: 4.9675 - val_loss: 38.5360 - val_mean_absolute_error: 5.5401\n",
            "Epoch 7/15\n",
            "39/39 [==============================] - 9s 224ms/step - loss: 35.5354 - mean_absolute_error: 5.0171 - val_loss: 39.9555 - val_mean_absolute_error: 5.6256\n",
            "Epoch 8/15\n",
            "39/39 [==============================] - 7s 172ms/step - loss: 33.7406 - mean_absolute_error: 4.8388 - val_loss: 38.1871 - val_mean_absolute_error: 5.5214\n",
            "Epoch 9/15\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 33.2330 - mean_absolute_error: 4.8341 - val_loss: 38.2189 - val_mean_absolute_error: 5.5282\n",
            "Epoch 10/15\n",
            "39/39 [==============================] - 8s 195ms/step - loss: 31.7902 - mean_absolute_error: 4.7216 - val_loss: 37.3359 - val_mean_absolute_error: 5.4724\n",
            "Epoch 11/15\n",
            "39/39 [==============================] - 7s 185ms/step - loss: 30.7141 - mean_absolute_error: 4.6274 - val_loss: 35.9001 - val_mean_absolute_error: 5.3749\n",
            "Epoch 12/15\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 27.0507 - mean_absolute_error: 4.3112 - val_loss: 32.9478 - val_mean_absolute_error: 5.0931\n",
            "Epoch 13/15\n",
            "39/39 [==============================] - 7s 179ms/step - loss: 22.6284 - mean_absolute_error: 3.8247 - val_loss: 33.7071 - val_mean_absolute_error: 5.1314\n",
            "Epoch 14/15\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 17.2926 - mean_absolute_error: 3.2652 - val_loss: 35.1895 - val_mean_absolute_error: 5.0026\n",
            "Epoch 15/15\n",
            "39/39 [==============================] - 6s 164ms/step - loss: 12.2096 - mean_absolute_error: 2.6708 - val_loss: 33.2129 - val_mean_absolute_error: 4.5829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5f8ac765c0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate([audio_features_test, test_sequences_matrix], ctargets_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")\n",
        "y_pred = model.predict([audio_features_test, test_sequences_matrix])\n",
        "print(np.sqrt(mean_squared_error(ctargets_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOcYlgqmVH0i",
        "outputId": "30fea04e-2547-466e-f9af-37f37d819c6a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 35ms/step - loss: 33.2129 - mean_absolute_error: 4.5829\n",
            "Test Loss: 33.2129020690918, Test Mean Absolute Error: 4.582897663116455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c5f7e758160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 26ms/step\n",
            "5.7630634500363636\n"
          ]
        }
      ]
    }
  ]
}