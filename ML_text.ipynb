{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "import re\n",
        "from tensorflow_hub import load, Module\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "iRI9JgLFyFBf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = 'data/'\n",
        "\n",
        "elmo = load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]"
      ],
      "metadata": {
        "id": "IUpIe6-80g3a"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split_df = pd.read_csv(prefix+'train_split_Depression_AVEC2017.csv')\n",
        "test_split_df = pd.read_csv(prefix+'dev_split_Depression_AVEC2017.csv')\n",
        "train_split_num = train_split_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "test_split_num = test_split_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "train_split_clabel = train_split_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "test_split_clabel = test_split_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "# train_split_clabel = train_split_df[['PHQ8_Score']]['PHQ8_Score'].tolist()\n",
        "# test_split_clabel = test_split_df[['PHQ8_Score']]['PHQ8_Score'].tolist()\n",
        "\n",
        "topics = []\n",
        "with open('questions.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        topics.append(line.strip('\\n').strip())"
      ],
      "metadata": {
        "id": "o0CqiUvM0jiv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    sentence = re.sub(r'\\(|\\)', '', sentence)\n",
        "    pattern = r'\\b(what|how|where|when|why|are|do|have|who|who\\'s|what\\'s|why\\'d|what\\'d)\\b(.*)$'\n",
        "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "    if match:\n",
        "        question = match.group(0).strip()\n",
        "        if question in topics:\n",
        "          return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(number, text_features, target, mode, text_targets):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv(prefix+'/{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "\n",
        "    time_range = []\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    start_time = 0\n",
        "    stop_time = 0\n",
        "\n",
        "    signal = []\n",
        "\n",
        "    global counter1, counter2\n",
        "\n",
        "    for t in transcript.itertuples():\n",
        "        if getattr(t,'speaker') == 'Ellie':\n",
        "            content = getattr(t,'value').strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response.strip())\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif getattr(t,'speaker') == 'Participant':\n",
        "            if 'scrubbed_entry' in getattr(t,'value'):\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +getattr(t,'value').split('\\n')[0].strip()\n",
        "\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      text_feature = elmo(tf.constant(responses))[\"elmo\"]\n",
        "      text_feature = tf.reduce_mean(text_feature, axis=1)\n",
        "\n",
        "      print(text_feature.shape)\n",
        "\n",
        "      text_features.append(text_feature)\n",
        "      text_targets.append(target)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rU12eKf10s8j"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter1 = 0\n",
        "counter2 = 0\n",
        "\n",
        "# training set\n",
        "text_features_train = []\n",
        "text_ctargets_train = []\n",
        "\n",
        "# test set\n",
        "text_features_test = []\n",
        "text_ctargets_test = []\n"
      ],
      "metadata": {
        "id": "UanrMY-8Yn0N"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(train_split_num)):\n",
        "     extract_features(train_split_num[index], text_features_train, train_split_clabel[index], 'train', text_ctargets_train)\n",
        "\n",
        "for index in range(len(test_split_num)):\n",
        "   extract_features(test_split_num[index], text_features_test, test_split_clabel[index], 'test', text_ctargets_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIol-ikt0z6G",
        "outputId": "c25e163e-bb68-4db8-8cec-3b753c29b381"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "(33, 1024)\n",
            "304\n",
            "(40, 1024)\n",
            "305\n",
            "(41, 1024)\n",
            "310\n",
            "(40, 1024)\n",
            "312\n",
            "(39, 1024)\n",
            "313\n",
            "(36, 1024)\n",
            "315\n",
            "(44, 1024)\n",
            "316\n",
            "(48, 1024)\n",
            "317\n",
            "(42, 1024)\n",
            "318\n",
            "(33, 1024)\n",
            "319\n",
            "(38, 1024)\n",
            "320\n",
            "(53, 1024)\n",
            "321\n",
            "(54, 1024)\n",
            "322\n",
            "(48, 1024)\n",
            "324\n",
            "(39, 1024)\n",
            "325\n",
            "(37, 1024)\n",
            "326\n",
            "(44, 1024)\n",
            "327\n",
            "(46, 1024)\n",
            "328\n",
            "(38, 1024)\n",
            "330\n",
            "(41, 1024)\n",
            "333\n",
            "(42, 1024)\n",
            "336\n",
            "(46, 1024)\n",
            "338\n",
            "(37, 1024)\n",
            "339\n",
            "(44, 1024)\n",
            "340\n",
            "(41, 1024)\n",
            "341\n",
            "(45, 1024)\n",
            "343\n",
            "(47, 1024)\n",
            "344\n",
            "(45, 1024)\n",
            "345\n",
            "(33, 1024)\n",
            "347\n",
            "(43, 1024)\n",
            "348\n",
            "(48, 1024)\n",
            "350\n",
            "(40, 1024)\n",
            "351\n",
            "(48, 1024)\n",
            "352\n",
            "(31, 1024)\n",
            "353\n",
            "(39, 1024)\n",
            "355\n",
            "(34, 1024)\n",
            "356\n",
            "(34, 1024)\n",
            "357\n",
            "(29, 1024)\n",
            "358\n",
            "(40, 1024)\n",
            "360\n",
            "(32, 1024)\n",
            "362\n",
            "(41, 1024)\n",
            "363\n",
            "(27, 1024)\n",
            "364\n",
            "(31, 1024)\n",
            "366\n",
            "(26, 1024)\n",
            "368\n",
            "(23, 1024)\n",
            "369\n",
            "(28, 1024)\n",
            "370\n",
            "(21, 1024)\n",
            "371\n",
            "(38, 1024)\n",
            "372\n",
            "(34, 1024)\n",
            "374\n",
            "(33, 1024)\n",
            "375\n",
            "(33, 1024)\n",
            "376\n",
            "(31, 1024)\n",
            "379\n",
            "(27, 1024)\n",
            "380\n",
            "(31, 1024)\n",
            "383\n",
            "(27, 1024)\n",
            "385\n",
            "(34, 1024)\n",
            "386\n",
            "(34, 1024)\n",
            "391\n",
            "(31, 1024)\n",
            "392\n",
            "(32, 1024)\n",
            "393\n",
            "(26, 1024)\n",
            "397\n",
            "(37, 1024)\n",
            "400\n",
            "(38, 1024)\n",
            "401\n",
            "(31, 1024)\n",
            "402\n",
            "(30, 1024)\n",
            "409\n",
            "(22, 1024)\n",
            "412\n",
            "(37, 1024)\n",
            "414\n",
            "(26, 1024)\n",
            "415\n",
            "(33, 1024)\n",
            "416\n",
            "(36, 1024)\n",
            "419\n",
            "(27, 1024)\n",
            "423\n",
            "(35, 1024)\n",
            "425\n",
            "(34, 1024)\n",
            "426\n",
            "(34, 1024)\n",
            "427\n",
            "(36, 1024)\n",
            "428\n",
            "(32, 1024)\n",
            "429\n",
            "(37, 1024)\n",
            "430\n",
            "(35, 1024)\n",
            "433\n",
            "(30, 1024)\n",
            "434\n",
            "(30, 1024)\n",
            "437\n",
            "(31, 1024)\n",
            "441\n",
            "(49, 1024)\n",
            "443\n",
            "(35, 1024)\n",
            "444\n",
            "(29, 1024)\n",
            "445\n",
            "(34, 1024)\n",
            "446\n",
            "(28, 1024)\n",
            "447\n",
            "(27, 1024)\n",
            "448\n",
            "(25, 1024)\n",
            "449\n",
            "(28, 1024)\n",
            "454\n",
            "(43, 1024)\n",
            "455\n",
            "(27, 1024)\n",
            "456\n",
            "(37, 1024)\n",
            "457\n",
            "(34, 1024)\n",
            "459\n",
            "(41, 1024)\n",
            "463\n",
            "(34, 1024)\n",
            "464\n",
            "(28, 1024)\n",
            "468\n",
            "(26, 1024)\n",
            "471\n",
            "(30, 1024)\n",
            "473\n",
            "(40, 1024)\n",
            "474\n",
            "(34, 1024)\n",
            "475\n",
            "(27, 1024)\n",
            "478\n",
            "(40, 1024)\n",
            "479\n",
            "(37, 1024)\n",
            "485\n",
            "(39, 1024)\n",
            "486\n",
            "(32, 1024)\n",
            "487\n",
            "(26, 1024)\n",
            "488\n",
            "(30, 1024)\n",
            "491\n",
            "(39, 1024)\n",
            "302\n",
            "(31, 1024)\n",
            "307\n",
            "(30, 1024)\n",
            "331\n",
            "(39, 1024)\n",
            "335\n",
            "(34, 1024)\n",
            "346\n",
            "(39, 1024)\n",
            "367\n",
            "(29, 1024)\n",
            "377\n",
            "(36, 1024)\n",
            "381\n",
            "(35, 1024)\n",
            "382\n",
            "(38, 1024)\n",
            "388\n",
            "(34, 1024)\n",
            "389\n",
            "(45, 1024)\n",
            "390\n",
            "(34, 1024)\n",
            "395\n",
            "(33, 1024)\n",
            "403\n",
            "(28, 1024)\n",
            "404\n",
            "(30, 1024)\n",
            "406\n",
            "(26, 1024)\n",
            "413\n",
            "(31, 1024)\n",
            "417\n",
            "(27, 1024)\n",
            "418\n",
            "(34, 1024)\n",
            "420\n",
            "(39, 1024)\n",
            "422\n",
            "(25, 1024)\n",
            "436\n",
            "(34, 1024)\n",
            "439\n",
            "(26, 1024)\n",
            "440\n",
            "(37, 1024)\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "(31, 1024)\n",
            "476\n",
            "(31, 1024)\n",
            "477\n",
            "(32, 1024)\n",
            "482\n",
            "(31, 1024)\n",
            "483\n",
            "(32, 1024)\n",
            "484\n",
            "(32, 1024)\n",
            "489\n",
            "(36, 1024)\n",
            "490\n",
            "(38, 1024)\n",
            "492\n",
            "(32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data imbalance\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "counter = 0\n",
        "\n",
        "cut = 10\n",
        "debt = 0\n",
        "\n",
        "for i in range(len(text_features_train)):\n",
        "  # regression\n",
        "    if text_ctargets_train[i] >= 10:\n",
        "        times = 3+debt if counter < 46 else 2+debt\n",
        "        for j in range(times):\n",
        "            if (j+1)*cut > len(text_features_train[i]):\n",
        "                debt+=1\n",
        "                continue\n",
        "            X_train.append(text_features_train[i][j*cut:(j+1)*cut])\n",
        "            Y_train.append(text_ctargets_train[i])\n",
        "            if debt > 0:\n",
        "                debt -= 1\n",
        "            counter+=1\n",
        "    else:\n",
        "        X_train.append(text_features_train[i][:cut])\n",
        "        Y_train.append(text_ctargets_train[i])\n",
        "\n",
        "\n",
        "for i in range(len(text_features_test)):\n",
        "    X_test.append(text_features_test[i][:cut])\n",
        "    Y_test.append(text_ctargets_test[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)"
      ],
      "metadata": {
        "id": "yxMwJ90ggQqo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('text_train_X_reg_new.npz', X_train)\n",
        "np.savez('text_train_Y_reg_new.npz', Y_train)\n",
        "np.savez('text_test_X_reg_new.npz', X_test)\n",
        "np.savez('text_test_Y_reg_new.npz', Y_test)"
      ],
      "metadata": {
        "id": "x6np55LIg-4e"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data imbalance\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "counter = 0\n",
        "\n",
        "cut = 10\n",
        "debt = 0\n",
        "\n",
        "for i in range(len(text_features_train)):\n",
        "  # classification\n",
        "    if text_ctargets_train[i] == 1:\n",
        "        times = 3+debt if counter < 46 else 2+debt\n",
        "        for j in range(times):\n",
        "            if (j+1)*cut > len(text_features_train[i]):\n",
        "                debt+=1\n",
        "                continue\n",
        "            X_train.append(text_features_train[i][j*cut:(j+1)*cut])\n",
        "            Y_train.append(text_ctargets_train[i])\n",
        "            if debt > 0:\n",
        "                debt -= 1\n",
        "            counter+=1\n",
        "    else:\n",
        "        X_train.append(text_features_train[i][:cut])\n",
        "        Y_train.append(text_ctargets_train[i])\n",
        "\n",
        "\n",
        "for i in range(len(text_features_test)):\n",
        "    X_test.append(text_features_test[i][:cut])\n",
        "    Y_test.append(text_ctargets_test[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)"
      ],
      "metadata": {
        "id": "hIxUt58aYTzz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('text_train_X_cla.npz', X_train)\n",
        "np.savez('text_train_Y_cla.npz', Y_train)\n",
        "np.savez('text_test_X_cla.npz', X_test)\n",
        "np.savez('text_test_Y_cla.npz', Y_test)"
      ],
      "metadata": {
        "id": "8DZrkh5MYeNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "rQr-PxZLY8RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('text_train_X_cla.npz', allow_pickle=True)['arr_0']\n",
        "Y_train = np.load('text_train_Y_cla.npz', allow_pickle=True)['arr_0']\n",
        "X_test = np.load('text_test_X_cla.npz', allow_pickle=True)['arr_0']\n",
        "Y_test = np.load('text_test_Y_cla.npz', allow_pickle=True)['arr_0']\n"
      ],
      "metadata": {
        "id": "1BUjQEk713ra"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(Y_train)\n",
        "test_y = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "MgjY3PIBjh52"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntOXuCU1g0e-",
        "outputId": "91d0928e-3e04-41f4-a380-179de2d7868d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(153, 10, 1024)\n",
            "(153,)\n",
            "(33, 10, 1024)\n",
            "(33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = tf.keras.layers.Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    inputs = Input(shape=(10, 1024))\n",
        "\n",
        "    forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "    backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "    bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "    output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(inputs)\n",
        "    final_hidden_state = forward_state + backward_state\n",
        "\n",
        "    x = attention(output, final_hidden_state)\n",
        "\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "wIwaQUvcHqfE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xJNVHw5nIous"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, train_y, epochs=20, validation_data=(X_test, test_y), batch_size=8)"
      ],
      "metadata": {
        "id": "bHtC3gKnJOuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0_A_7pRRpWy",
        "outputId": "09184cee-5bae-4573-d781-e02588a95aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(Y_test, predicted_1))\n",
        "print(confusion_matrix(Y_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwQSQ94v4_og",
        "outputId": "81fdca18-ce5f-4a22-a5f3-87376b75ce20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.86      0.78        21\n",
            "           1       0.62      0.42      0.50        12\n",
            "\n",
            "    accuracy                           0.70        33\n",
            "   macro avg       0.67      0.64      0.64        33\n",
            "weighted avg       0.69      0.70      0.68        33\n",
            "\n",
            "[[18  3]\n",
            " [ 7  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_textz_class.keras\")"
      ],
      "metadata": {
        "id": "9U-9nTOtVtCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "nUIwbnLkY0e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('text_train_X_reg.npz', allow_pickle=True)['arr_0']\n",
        "Y_train = np.load('text_train_Y_reg.npz', allow_pickle=True)['arr_0']\n",
        "X_test = np.load('text_test_X_reg.npz', allow_pickle=True)['arr_0']\n",
        "Y_test = np.load('text_test_Y_reg.npz', allow_pickle=True)['arr_0']\n"
      ],
      "metadata": {
        "id": "51YkXLUpxvJ0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NFW6zVsZDJY",
        "outputId": "e93226d0-67cc-4802-9beb-47af7a7095ec"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(154, 10, 1024)\n",
            "(154,)\n",
            "(33, 10, 1024)\n",
            "(33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = tf.keras.layers.Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    inputs = Input(shape=(10, 1024))\n",
        "\n",
        "    forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "    backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "    bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "    output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(inputs)\n",
        "    final_hidden_state = forward_state + backward_state\n",
        "\n",
        "    x = attention(output, final_hidden_state)\n",
        "\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "LxS1o39BZk8X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "model.fit(X_train, Y_train, epochs=50, validation_data=(X_test, Y_test), batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fKsc-r5ZnY3",
        "outputId": "1107d239-056a-4416-cb50-dc622d6b10ad"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 6s 60ms/step - loss: 106.3311 - mean_absolute_error: 8.5099 - val_loss: 101.4542 - val_mean_absolute_error: 7.5811\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 105.9236 - mean_absolute_error: 8.4839 - val_loss: 100.9199 - val_mean_absolute_error: 7.5562\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 105.4691 - mean_absolute_error: 8.4679 - val_loss: 100.3793 - val_mean_absolute_error: 7.5310\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 104.4920 - mean_absolute_error: 8.4251 - val_loss: 99.8349 - val_mean_absolute_error: 7.5055\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 43ms/step - loss: 104.0555 - mean_absolute_error: 8.3906 - val_loss: 99.2664 - val_mean_absolute_error: 7.4786\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 103.0318 - mean_absolute_error: 8.3584 - val_loss: 98.6646 - val_mean_absolute_error: 7.4498\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 102.3047 - mean_absolute_error: 8.3261 - val_loss: 97.9764 - val_mean_absolute_error: 7.4168\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 101.2637 - mean_absolute_error: 8.2686 - val_loss: 97.1872 - val_mean_absolute_error: 7.3784\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 100.6500 - mean_absolute_error: 8.2384 - val_loss: 96.3427 - val_mean_absolute_error: 7.3371\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 99.2638 - mean_absolute_error: 8.1745 - val_loss: 95.3561 - val_mean_absolute_error: 7.2883\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 97.5277 - mean_absolute_error: 8.1110 - val_loss: 94.2687 - val_mean_absolute_error: 7.2342\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 97.2602 - mean_absolute_error: 8.0773 - val_loss: 93.1238 - val_mean_absolute_error: 7.1767\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 95.3857 - mean_absolute_error: 7.9993 - val_loss: 91.8068 - val_mean_absolute_error: 7.1098\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 93.8010 - mean_absolute_error: 7.9123 - val_loss: 90.2857 - val_mean_absolute_error: 7.0315\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 90.7538 - mean_absolute_error: 7.7806 - val_loss: 88.4037 - val_mean_absolute_error: 6.9327\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 87.4304 - mean_absolute_error: 7.6451 - val_loss: 86.2046 - val_mean_absolute_error: 6.8254\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 84.4368 - mean_absolute_error: 7.4804 - val_loss: 83.5971 - val_mean_absolute_error: 6.7147\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 81.7436 - mean_absolute_error: 7.3090 - val_loss: 80.5756 - val_mean_absolute_error: 6.6025\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 79.0402 - mean_absolute_error: 7.2480 - val_loss: 77.0677 - val_mean_absolute_error: 6.4675\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 73.1033 - mean_absolute_error: 6.9136 - val_loss: 73.3316 - val_mean_absolute_error: 6.3129\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 67.4879 - mean_absolute_error: 6.6296 - val_loss: 69.3733 - val_mean_absolute_error: 6.1368\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 60.1537 - mean_absolute_error: 6.2776 - val_loss: 64.3987 - val_mean_absolute_error: 5.9158\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 56.6886 - mean_absolute_error: 6.0261 - val_loss: 59.8868 - val_mean_absolute_error: 5.7879\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 52.4928 - mean_absolute_error: 5.7686 - val_loss: 56.5805 - val_mean_absolute_error: 5.7208\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 49.2974 - mean_absolute_error: 5.6327 - val_loss: 53.5710 - val_mean_absolute_error: 5.6601\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 47.3500 - mean_absolute_error: 5.5450 - val_loss: 51.9734 - val_mean_absolute_error: 5.6445\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 2s 80ms/step - loss: 48.6440 - mean_absolute_error: 5.5884 - val_loss: 50.7467 - val_mean_absolute_error: 5.6509\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 41.0175 - mean_absolute_error: 5.1975 - val_loss: 49.8319 - val_mean_absolute_error: 5.6558\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 43.0503 - mean_absolute_error: 5.1837 - val_loss: 49.5821 - val_mean_absolute_error: 5.6592\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 41.8564 - mean_absolute_error: 5.2153 - val_loss: 48.6684 - val_mean_absolute_error: 5.6635\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 47.0785 - mean_absolute_error: 5.6223 - val_loss: 48.7029 - val_mean_absolute_error: 5.6635\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 44.8038 - mean_absolute_error: 5.4164 - val_loss: 48.4252 - val_mean_absolute_error: 5.6658\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 46.4119 - mean_absolute_error: 5.3040 - val_loss: 47.9900 - val_mean_absolute_error: 5.6689\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 41.9934 - mean_absolute_error: 5.3211 - val_loss: 47.9808 - val_mean_absolute_error: 5.6695\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 44.1186 - mean_absolute_error: 5.3635 - val_loss: 47.6718 - val_mean_absolute_error: 5.6724\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 43.7259 - mean_absolute_error: 5.2339 - val_loss: 47.6298 - val_mean_absolute_error: 5.6732\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 38ms/step - loss: 41.3606 - mean_absolute_error: 5.1919 - val_loss: 47.2079 - val_mean_absolute_error: 5.6759\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 41.1276 - mean_absolute_error: 5.2085 - val_loss: 46.6728 - val_mean_absolute_error: 5.6800\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 39.7077 - mean_absolute_error: 5.0724 - val_loss: 46.3257 - val_mean_absolute_error: 5.6826\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 36.9420 - mean_absolute_error: 4.9469 - val_loss: 46.1208 - val_mean_absolute_error: 5.6838\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 74ms/step - loss: 46.2460 - mean_absolute_error: 5.5504 - val_loss: 45.8761 - val_mean_absolute_error: 5.6853\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 66ms/step - loss: 39.6124 - mean_absolute_error: 5.1847 - val_loss: 46.0166 - val_mean_absolute_error: 5.6834\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 36.3620 - mean_absolute_error: 4.8088 - val_loss: 45.6859 - val_mean_absolute_error: 5.6865\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 39.0135 - mean_absolute_error: 5.0975 - val_loss: 45.6035 - val_mean_absolute_error: 5.6871\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 36.4011 - mean_absolute_error: 4.9301 - val_loss: 45.3739 - val_mean_absolute_error: 5.6897\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 43.7822 - mean_absolute_error: 5.2319 - val_loss: 45.4928 - val_mean_absolute_error: 5.6880\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 38.9950 - mean_absolute_error: 5.0320 - val_loss: 45.8450 - val_mean_absolute_error: 5.6848\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 42.0396 - mean_absolute_error: 5.2012 - val_loss: 45.7178 - val_mean_absolute_error: 5.6856\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 58ms/step - loss: 37.1923 - mean_absolute_error: 4.8366 - val_loss: 45.4960 - val_mean_absolute_error: 5.6877\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 65ms/step - loss: 40.5953 - mean_absolute_error: 5.1316 - val_loss: 45.3943 - val_mean_absolute_error: 5.6889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7868c9372fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9JS_d_jZ5AX",
        "outputId": "0f3622c9-3430-460d-dcd7-5308f8556ac6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step - loss: 45.3943 - mean_absolute_error: 5.6889\n",
            "Test Loss: 45.3942756652832, Test Mean Absolute Error: 5.688858985900879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exTBGToQbQ1O",
        "outputId": "2733e9a7-0666-4ed0-d658-c697800df5c8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sqrt(mean_squared_error(Y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bEhSzLObYur",
        "outputId": "e505939c-3f20-4435-a612-fbec7cf54070"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.737527311587194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_text_regression.keras\")"
      ],
      "metadata": {
        "id": "VwT1gL3obaOy"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}