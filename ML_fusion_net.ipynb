{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWUpjmddpQYN",
        "outputId": "48f8cc51-d208-4146-8428-5f845c961761"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=c186b3e91485ee79c1caf7dd7d4f256f77c28eed10b9387b626ea1b59b2a9c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BrtmnpkqnxY0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "from python_speech_features import *\n",
        "import re\n",
        "from tensorflow_hub import load, Module\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/data_ML5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_q1Ng_9n5Tt",
        "outputId": "5ff14419-bb59-466e-8ad8-372364612d13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/data_ML5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train_split_Depression_AVEC2017.csv')\n",
        "test_df = pd.read_csv('dev_split_Depression_AVEC2017.csv')"
      ],
      "metadata": {
        "id": "Flmz-l8roQ3v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "test_id = test_df[['Participant_ID']]['Participant_ID'].tolist()\n",
        "# train_label = train_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "# test_label = test_df[['PHQ8_Binary']]['PHQ8_Binary'].tolist()\n",
        "train_label = train_df[['PHQ8_Score']]['PHQ8_Score'].tolist()\n",
        "test_label = test_df[['PHQ8_Score']]['PHQ8_Score'].tolist()"
      ],
      "metadata": {
        "id": "F0kmPjWZwhlr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo = load(\"https://tfhub.dev/google/elmo/3\").signatures[\"default\"]"
      ],
      "metadata": {
        "id": "sqJAQF0Q3-V7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "train_features = []\n",
        "train_targets = []\n",
        "\n",
        "# test set\n",
        "test_features = []\n",
        "test_targets = []\n",
        "\n",
        "features_whole = []\n",
        "targets_whole = []\n",
        "whole_split_num = train_id + test_id\n",
        "whole_targets = train_label + test_label\n",
        "\n",
        "counter_train = 0\n",
        "counter_test = 0\n",
        "debt = 0"
      ],
      "metadata": {
        "id": "8akwUx70ww85"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = []\n",
        "with open('questions.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        topics.append(line.strip('\\n').strip())"
      ],
      "metadata": {
        "id": "-dDYofyv08e_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_topics(sentence):\n",
        "    sentence = re.sub(r'\\(|\\)', '', sentence)\n",
        "    pattern = r'\\b(what|how|where|when|why|are|do|have|who|who\\'s|what\\'s|why\\'d|what\\'d)\\b(.*)$'\n",
        "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "    if match:\n",
        "        question = match.group(0).strip()\n",
        "        if question in topics:\n",
        "          return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(number, features, target, targets, mode):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    wavefile = wave.open('{0}_AUDIO.wav'.format(number, 'r'))\n",
        "    framerate = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "\n",
        "    time_range = []\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    start_time = 0\n",
        "    stop_time = 0\n",
        "    signal = []\n",
        "\n",
        "    global counter_train, counter_test\n",
        "\n",
        "    for row in transcript.itertuples():\n",
        "        if row.speaker == 'Ellie':\n",
        "\n",
        "            content = row.value.strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response.strip())\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif row.speaker == 'Participant':\n",
        "            if 'scrubbed_entry' in row.value:\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +row.value.split('\\n')[0].strip()\n",
        "            start_time = int(row.start_time*framerate)\n",
        "            stop_time = int(row.stop_time*framerate)\n",
        "            signal = np.hstack((signal, wave_data[start_time:stop_time].astype(np.float64)))\n",
        "    clip = framerate*1*15\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      text_feature = elmo(tf.constant(responses))[\"elmo\"]\n",
        "      text_feature = tf.reduce_mean(text_feature, axis=0)\n",
        " #      if target == 1 and mode == 'train':\n",
        "      if target >= 10 and mode == 'train':\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "              melspec = librosa.feature.melspectrogram(y=signal[clip*i:clip*(i+1)], n_mels=80,sr=framerate)\n",
        "              text_f = text_feature[i*10:(i+1)*10]\n",
        "              features.append([text_f.numpy(), melspec])\n",
        "              targets.append(target)\n",
        "              counter_train+=1\n",
        "      else:\n",
        "          melspec = librosa.feature.melspectrogram(y=signal[:clip], n_mels=80, sr=framerate)\n",
        "          text_f = text_feature[:10]\n",
        "          features.append([text_f.numpy(), melspec])\n",
        "          targets.append(target)"
      ],
      "metadata": {
        "id": "FheXV1zp1gZL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_whole(number, features, target, targets):\n",
        "    print(number)\n",
        "    transcript = pd.read_csv('{0}_TRANSCRIPT.csv'.format(number), sep='\\t').fillna('')\n",
        "\n",
        "    wavefile = wave.open('{0}_AUDIO.wav'.format(number, 'r'))\n",
        "    framerate = wavefile.getframerate()\n",
        "    nframes = wavefile.getnframes()\n",
        "    wave_data = np.frombuffer(wavefile.readframes(nframes), dtype=np.short)\n",
        "\n",
        "    time_range = []\n",
        "    responses = []\n",
        "    response = ''\n",
        "    response_flag = False\n",
        "    start_time = 0\n",
        "    stop_time = 0\n",
        "    signal = []\n",
        "\n",
        "    global counter_train, counter_test\n",
        "\n",
        "    for row in transcript.itertuples():\n",
        "        if row.speaker == 'Ellie':\n",
        "\n",
        "            content = row.value.strip()\n",
        "            if identify_topics(content):\n",
        "                response_flag = True\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response.strip())\n",
        "                response = ''\n",
        "            elif response_flag and len(content.split()) > 4:\n",
        "                response_flag = False\n",
        "                if len(response) != 0:\n",
        "                    responses.append(response)\n",
        "                response = ''\n",
        "        elif row.speaker == 'Participant':\n",
        "            if 'scrubbed_entry' in row.value:\n",
        "                continue\n",
        "            elif response_flag:\n",
        "                response +=' ' +row.value.split('\\n')[0].strip()\n",
        "            start_time = int(row.start_time*framerate)\n",
        "            stop_time = int(row.stop_time*framerate)\n",
        "            signal = np.hstack((signal, wave_data[start_time:stop_time].astype(np.float64)))\n",
        "    clip = framerate*1*15\n",
        "    if len(responses) == 0:\n",
        "      print(\"Empty\")\n",
        "    else:\n",
        "      text_feature = elmo(tf.constant(responses))[\"elmo\"]\n",
        "      text_feature = tf.reduce_mean(text_feature, axis=0)\n",
        " #     if target == 1:\n",
        "      if target >= 10:\n",
        "        times = 3 if counter_train < 48 else 2\n",
        "        for i in range(times):\n",
        "              melspec = librosa.feature.melspectrogram(y=signal[clip*i:clip*(i+1)], n_mels=80,sr=framerate)\n",
        "              features.append([text_feature[i*10:(i+1)*10], melspec])\n",
        "              targets.append(target)\n",
        "              counter_train+=1\n",
        "      else:\n",
        "          melspec = librosa.feature.melspectrogram(y=signal[:clip], n_mels=80, sr=framerate)\n",
        "          features.append([text_feature[:10], melspec])\n",
        "          targets.append(target)"
      ],
      "metadata": {
        "id": "wvj-t4mb-mLj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_id)):\n",
        "    extract_features(train_id[i], train_features, train_label[i], train_targets, 'train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mX0tZee0qzc",
        "outputId": "07637df5-990f-4394-c32e-71b1ad0c1ce5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "304\n",
            "305\n",
            "310\n",
            "312\n",
            "313\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "330\n",
            "333\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "343\n",
            "344\n",
            "345\n",
            "347\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "360\n",
            "362\n",
            "363\n",
            "364\n",
            "366\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "374\n",
            "375\n",
            "376\n",
            "379\n",
            "380\n",
            "383\n",
            "385\n",
            "386\n",
            "391\n",
            "392\n",
            "393\n",
            "397\n",
            "400\n",
            "401\n",
            "402\n",
            "409\n",
            "412\n",
            "414\n",
            "415\n",
            "416\n",
            "419\n",
            "423\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "433\n",
            "434\n",
            "437\n",
            "441\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "459\n",
            "463\n",
            "464\n",
            "468\n",
            "471\n",
            "473\n",
            "474\n",
            "475\n",
            "478\n",
            "479\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_train_samples_regression.npz', train_features)\n",
        "np.savez('fuse_train_labels_regression.npz', train_targets)"
      ],
      "metadata": {
        "id": "MSlSM2wmt32n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_id)):\n",
        "    extract_features(test_id[i], test_features, test_label[i], test_targets, 'test')\n",
        "\n",
        "print(np.shape(train_targets), np.shape(test_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBqKEZgztERA",
        "outputId": "b8d9df99-7855-4d64-cffb-bcb803396045"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "302\n",
            "307\n",
            "331\n",
            "335\n",
            "346\n",
            "367\n",
            "377\n",
            "381\n",
            "382\n",
            "388\n",
            "389\n",
            "390\n",
            "395\n",
            "403\n",
            "404\n",
            "406\n",
            "413\n",
            "417\n",
            "418\n",
            "420\n",
            "422\n",
            "436\n",
            "439\n",
            "440\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "476\n",
            "477\n",
            "482\n",
            "483\n",
            "484\n",
            "489\n",
            "490\n",
            "492\n",
            "(154,) (33,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_test_samples_regression.npz', test_features)\n",
        "np.savez('fuse_test_labels_regression.npz', test_targets)"
      ],
      "metadata": {
        "id": "aRF1J85Bw9D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(whole_split_num)):\n",
        "  extract_features_whole(whole_split_num[index], features_whole, whole_targets[index], targets_whole)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCldF81x_XuZ",
        "outputId": "2c22fe5f-5029-4b16-a681-5122a663e588"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "304\n",
            "305\n",
            "310\n",
            "312\n",
            "313\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "330\n",
            "333\n",
            "336\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "343\n",
            "344\n",
            "345\n",
            "347\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "360\n",
            "362\n",
            "363\n",
            "364\n",
            "366\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "374\n",
            "375\n",
            "376\n",
            "379\n",
            "380\n",
            "383\n",
            "385\n",
            "386\n",
            "391\n",
            "392\n",
            "393\n",
            "397\n",
            "400\n",
            "401\n",
            "402\n",
            "409\n",
            "412\n",
            "414\n",
            "415\n",
            "416\n",
            "419\n",
            "423\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "433\n",
            "434\n",
            "437\n",
            "441\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "459\n",
            "463\n",
            "464\n",
            "468\n",
            "471\n",
            "473\n",
            "474\n",
            "475\n",
            "478\n",
            "479\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "491\n",
            "302\n",
            "307\n",
            "331\n",
            "335\n",
            "346\n",
            "367\n",
            "377\n",
            "381\n",
            "382\n",
            "388\n",
            "389\n",
            "390\n",
            "395\n",
            "403\n",
            "404\n",
            "406\n",
            "413\n",
            "417\n",
            "418\n",
            "420\n",
            "422\n",
            "436\n",
            "439\n",
            "440\n",
            "451\n",
            "Empty\n",
            "458\n",
            "Empty\n",
            "472\n",
            "476\n",
            "477\n",
            "482\n",
            "483\n",
            "484\n",
            "489\n",
            "490\n",
            "492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('fuse_whole_samples_regression.npz', features_whole)\n",
        "np.savez('fuse_whole_labels_regression.npz', targets_whole)"
      ],
      "metadata": {
        "id": "c4ydT1_hyyPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "U1-0rN2M5dJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('fuse_train_samples_classification.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('fuse_test_samples_classification.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_classification.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_classification.npz', allow_pickle=True)['arr_0']\n",
        "\n",
        "X_train = np.array(features_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_train = np.array(targets_train)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "32fcmxIgjbW-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train[i][1]]).astype('float32')\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test[i][1]]).astype('float32')"
      ],
      "metadata": {
        "id": "rOEtuG0imFU4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(Y_train)\n",
        "test_y = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "y6EsDaCrAh4M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = []\n",
        "audio_features = []\n",
        "for i in range(len(X_train)):\n",
        "  text_features.append(X_train[i][0])\n",
        "  audio_features.append(X_train[i][1])\n",
        "\n",
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "for i in range(len(X_test)):\n",
        "  text_features_test.append(X_test[i][0])\n",
        "  audio_features_test.append(X_test[i][1])\n",
        "\n",
        "text_features = np.array(text_features)\n",
        "audio_features = np.array(audio_features)\n",
        "\n",
        "text_features_test = np.array(text_features_test)\n",
        "audio_features_test = np.array(audio_features_test)"
      ],
      "metadata": {
        "id": "tHEWLM80CGyw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "input1 = Input(shape=(80, 469, 1))\n",
        "x1 = Conv2D(32, (1, 7), activation='relu', input_shape=(80, 469, 1))(input1)\n",
        "x1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(x1)\n",
        "x1 = Conv2D(32, (1, 7), activation='relu')(x1)\n",
        "x1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=(10, 1024))\n",
        "\n",
        "forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(input2)\n",
        "final_hidden_state = forward_state + backward_state\n",
        "\n",
        "x2 = attention(output, final_hidden_state)\n",
        "\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = tf.keras.layers.Dense(2, activation='softmax')(merged)"
      ],
      "metadata": {
        "id": "V1NHfVLN_np_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input1, input2], outputs=outputs)"
      ],
      "metadata": {
        "id": "6u4pK8AB5HwG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "model.fit([audio_features, text_features], train_y, validation_data=([audio_features_test, text_features_test], test_y), epochs=10, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPIf6BT3a8tX",
        "outputId": "6e1e00bf-8af7-4b56-d0cf-5a8bf02645b9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "76/76 [==============================] - 8s 38ms/step - loss: 0.7237 - accuracy: 0.4079 - val_loss: 0.6818 - val_accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "76/76 [==============================] - 2s 31ms/step - loss: 0.6780 - accuracy: 0.5329 - val_loss: 0.6645 - val_accuracy: 0.6061\n",
            "Epoch 3/10\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.6162 - accuracy: 0.7368 - val_loss: 0.6945 - val_accuracy: 0.5152\n",
            "Epoch 4/10\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.5596 - accuracy: 0.7895 - val_loss: 0.6662 - val_accuracy: 0.6364\n",
            "Epoch 5/10\n",
            "76/76 [==============================] - 3s 35ms/step - loss: 0.4891 - accuracy: 0.8553 - val_loss: 0.6847 - val_accuracy: 0.6061\n",
            "Epoch 6/10\n",
            "76/76 [==============================] - 2s 31ms/step - loss: 0.4164 - accuracy: 0.9013 - val_loss: 0.6622 - val_accuracy: 0.5455\n",
            "Epoch 7/10\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.3956 - accuracy: 0.8553 - val_loss: 0.6639 - val_accuracy: 0.5455\n",
            "Epoch 8/10\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.2847 - accuracy: 0.9539 - val_loss: 0.6780 - val_accuracy: 0.6061\n",
            "Epoch 9/10\n",
            "76/76 [==============================] - 2s 25ms/step - loss: 0.2412 - accuracy: 0.9474 - val_loss: 0.6769 - val_accuracy: 0.5455\n",
            "Epoch 10/10\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.1898 - accuracy: 1.0000 - val_loss: 0.7503 - val_accuracy: 0.6364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f24f91a860>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([audio_features_test, text_features_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLRP2rgsdesz",
        "outputId": "72287343-a6d3-4746-e8cf-cd13f8252e92"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_1 = [1 if x[1] > x[0] else 0 for x in y_pred]\n",
        "print(classification_report(Y_test, predicted_1))\n",
        "print(confusion_matrix(Y_test, predicted_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPYPCL4OsYEl",
        "outputId": "8f0f9651-7a4e-4d8f-bdfd-7a3257b15194"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.57      0.67        21\n",
            "           1       0.50      0.75      0.60        12\n",
            "\n",
            "    accuracy                           0.64        33\n",
            "   macro avg       0.65      0.66      0.63        33\n",
            "weighted avg       0.69      0.64      0.64        33\n",
            "\n",
            "[[12  9]\n",
            " [ 3  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"fusion_classification_model.keras\")"
      ],
      "metadata": {
        "id": "frR5PsCysdSP"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "pHJiR_ucunRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = np.load('fuse_train_samples_regression.npz', allow_pickle=True)['arr_0']\n",
        "features_test = np.load('fuse_test_samples_regression.npz', allow_pickle=True)['arr_0']\n",
        "targets_train = np.load('fuse_train_labels_regression.npz', allow_pickle=True)['arr_0']\n",
        "ctargets_test = np.load('fuse_test_labels_regression.npz', allow_pickle=True)['arr_0']\n",
        "\n",
        "X_train = np.array(features_train)\n",
        "X_test = np.array(features_test)\n",
        "Y_train = np.array(targets_train)\n",
        "Y_test = np.array(ctargets_test)"
      ],
      "metadata": {
        "id": "NJsNRnyPuoZ4"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train[i][1]]).astype('float32')\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i][1] = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test[i][1]]).astype('float32')"
      ],
      "metadata": {
        "id": "tGifWn_NuzX-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = []\n",
        "audio_features = []\n",
        "for i in range(len(X_train)):\n",
        "  text_features.append(X_train[i][0])\n",
        "  audio_features.append(X_train[i][1])\n",
        "\n",
        "text_features_test = []\n",
        "audio_features_test = []\n",
        "for i in range(len(X_test)):\n",
        "  text_features_test.append(X_test[i][0])\n",
        "  audio_features_test.append(X_test[i][1])\n",
        "\n",
        "text_features = np.array(text_features)\n",
        "audio_features = np.array(audio_features)\n",
        "\n",
        "text_features_test = np.array(text_features_test)\n",
        "audio_features_test = np.array(audio_features_test)"
      ],
      "metadata": {
        "id": "e_zZ3m50vXOL"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer_1(tf.keras.Model):\n",
        "    def __init__(self, hidden_dims):\n",
        "        super(AttentionLayer_1, self).__init__()\n",
        "\n",
        "        self.linear_layer = Dense(hidden_dims)\n",
        "        self.relu_layer = tf.keras.layers.ReLU()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_layer(inputs)\n",
        "        x = self.relu_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def attention(output, final_hidden_state):\n",
        "    lstm_hidden = tf.expand_dims(tf.convert_to_tensor(final_hidden_state), 1)\n",
        "    attention_layer = AttentionLayer_1(hidden_dims=128)\n",
        "    atten_w = attention_layer(lstm_hidden)\n",
        "    tanh = tf.keras.activations.tanh(output)\n",
        "    c = tf.matmul(atten_w, tf.transpose(tanh, (0, 2, 1)))\n",
        "    softmax_w = tf.keras.activations.softmax(c, axis=-1)\n",
        "    context = tf.matmul(softmax_w, output)\n",
        "    result = tf.squeeze(context, axis=1)\n",
        "    return result\n",
        "\n",
        "input1 = Input(shape=(80, 469, 1))\n",
        "x1 = Conv2D(32, (1, 7), activation='relu', input_shape=(80, 469, 1))(input1)\n",
        "x1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(x1)\n",
        "x1 = Conv2D(32, (1, 7), activation='relu')(x1)\n",
        "x1 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "x1 = Dense(128, activation='relu')(x1)\n",
        "\n",
        "input2 = Input(shape=(10, 1024))\n",
        "\n",
        "forward_layer = LSTM(128,  activation='relu', dropout=0.5, return_sequences=True, return_state=True)\n",
        "backward_layer = LSTM(128, activation='relu',  dropout=0.5, return_sequences=True, go_backwards=True, return_state=True)\n",
        "bidir = Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(10, 1024), merge_mode='sum')\n",
        "\n",
        "output, forward_state, forward_sell_tate, backward_state, backward_sell_state = bidir(input2)\n",
        "final_hidden_state = forward_state + backward_state\n",
        "\n",
        "x2 = attention(output, final_hidden_state)\n",
        "\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "x2 = Dense(128, activation='relu')(x2)\n",
        "\n",
        "merged = Concatenate(axis=1)([x1, x2])\n",
        "outputs = tf.keras.layers.Dense(1, activation='linear')(merged)"
      ],
      "metadata": {
        "id": "lMJzGWC6vbNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input1, input2], outputs=outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "model.fit([audio_features, text_features], Y_train, validation_data=([audio_features_test, text_features_test], Y_test), epochs=20, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txWeRAlnwRoA",
        "outputId": "a2484285-bbea-46ab-c5aa-7303c454319c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "76/76 [==============================] - 7s 36ms/step - loss: 50.3197 - mean_absolute_error: 5.6373 - val_loss: 44.3904 - val_mean_absolute_error: 5.6880\n",
            "Epoch 2/20\n",
            "76/76 [==============================] - 3s 33ms/step - loss: 35.2082 - mean_absolute_error: 4.8067 - val_loss: 47.5834 - val_mean_absolute_error: 5.9423\n",
            "Epoch 3/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 28.3283 - mean_absolute_error: 4.2968 - val_loss: 43.8997 - val_mean_absolute_error: 5.6218\n",
            "Epoch 4/20\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 22.6990 - mean_absolute_error: 3.8631 - val_loss: 41.4916 - val_mean_absolute_error: 5.3305\n",
            "Epoch 5/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 15.6606 - mean_absolute_error: 3.0758 - val_loss: 43.0306 - val_mean_absolute_error: 5.2876\n",
            "Epoch 6/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 11.3086 - mean_absolute_error: 2.5945 - val_loss: 40.9592 - val_mean_absolute_error: 5.4433\n",
            "Epoch 7/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 6.0403 - mean_absolute_error: 1.8577 - val_loss: 38.3322 - val_mean_absolute_error: 5.1518\n",
            "Epoch 8/20\n",
            "76/76 [==============================] - 2s 28ms/step - loss: 3.9494 - mean_absolute_error: 1.4737 - val_loss: 44.9923 - val_mean_absolute_error: 5.7881\n",
            "Epoch 9/20\n",
            "76/76 [==============================] - 2s 31ms/step - loss: 2.3103 - mean_absolute_error: 1.1293 - val_loss: 39.0046 - val_mean_absolute_error: 5.2975\n",
            "Epoch 10/20\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 1.2670 - mean_absolute_error: 0.8453 - val_loss: 38.5143 - val_mean_absolute_error: 5.2236\n",
            "Epoch 11/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7869 - mean_absolute_error: 0.6288 - val_loss: 37.8890 - val_mean_absolute_error: 5.1939\n",
            "Epoch 12/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.6396 - mean_absolute_error: 0.5741 - val_loss: 38.5227 - val_mean_absolute_error: 5.2345\n",
            "Epoch 13/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.4162 - mean_absolute_error: 0.4893 - val_loss: 39.8651 - val_mean_absolute_error: 5.3068\n",
            "Epoch 14/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.3016 - mean_absolute_error: 0.4036 - val_loss: 38.6890 - val_mean_absolute_error: 5.2073\n",
            "Epoch 15/20\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.2113 - mean_absolute_error: 0.3638 - val_loss: 38.8685 - val_mean_absolute_error: 5.2044\n",
            "Epoch 16/20\n",
            "76/76 [==============================] - 2s 32ms/step - loss: 0.2772 - mean_absolute_error: 0.4057 - val_loss: 39.3930 - val_mean_absolute_error: 5.2554\n",
            "Epoch 17/20\n",
            "76/76 [==============================] - 2s 27ms/step - loss: 0.2465 - mean_absolute_error: 0.3861 - val_loss: 38.4208 - val_mean_absolute_error: 5.1599\n",
            "Epoch 18/20\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.1686 - mean_absolute_error: 0.3317 - val_loss: 39.2868 - val_mean_absolute_error: 5.2288\n",
            "Epoch 19/20\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.1810 - mean_absolute_error: 0.3428 - val_loss: 39.7811 - val_mean_absolute_error: 5.2868\n",
            "Epoch 20/20\n",
            "76/76 [==============================] - 2s 26ms/step - loss: 0.2397 - mean_absolute_error: 0.4009 - val_loss: 38.0638 - val_mean_absolute_error: 5.1077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78f24eaf5ae0>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mean_absolute_error = model.evaluate([audio_features_test, text_features_test], Y_test)\n",
        "print(f\"Test Loss: {loss}, Test Mean Absolute Error: {mean_absolute_error}\")\n",
        "y_pred = model.predict([audio_features_test, text_features_test])\n",
        "print(np.sqrt(mean_squared_error(Y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-xAxS6mw1Hz",
        "outputId": "d7c8024d-e476-4d37-bc1f-dc6fefd972a4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 13ms/step - loss: 35.8677 - mean_absolute_error: 5.0579\n",
            "Test Loss: 35.86766052246094, Test Mean Absolute Error: 5.057867527008057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78f1cc37f010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step\n",
            "5.988961437922379\n"
          ]
        }
      ]
    }
  ]
}